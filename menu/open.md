---
layout: page
title: Material
---

Bellow you can find scripts for running experiments or analyzing data, and other shared material.

---
# Machine Learning Courses
---


If you are beginner in Machine Learning and you want to get a solid mathematical background in order to do Machine learning, this is a list of very good books that I used myself : 
* [Mathematics for Machine Learning](https://mml-book.com). by [Marc Peter Deisenroth](https://twitter.com/mpd37), [A Aldo Faisal](https://twitter.com/analogaldo), and [Cheng Soon Ong](https://twitter.com/ChengSoonOng).

	* You can find here [slides](https://sites.google.com/view/marcdeisenroth/teaching/201819/foundations-of-machine-learning?authuser=0) for the Foundation of Machine Learning Course given by **Marc Peter Deisenroth** from Imperial College London. 


The book is not intended to cover advanced machine learning techniques because there are already plenty of books doing this. Instead, is to provide the necessary mathematical skills to read those other books.
* [Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/people/cmbishop/#!prml-book) by [Christopher Bishop](https://twitter.com/ChrisBishopMSFT).
* Machine Learning: A Probabilistic Perspective by **Kevin P. Murphy.**
* [Understanding Machine Learning From Theory to Algorithms](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=2ahUKEwio5s3M86zfAhXqxoUKHXm7A_oQFjAAegQIAxAC&url=https%3A%2F%2Fwww.cs.huji.ac.il%2F~shais%2FUnderstandingMachineLearning%2Funderstanding-machine-learning-theory-algorithms.pdf&usg=AOvVaw3w_XtL2On_1VFSyDmcU0Qn) by **Shai Shalev-Shwartz** and **Shai Ben-David.**


---
# Deep Learning Courses
---


* You can find here [slides](https://fleuret.org/ammi-2018/) and a virtual machine for an introductory course to deep learning given in the African Master’s of Machine Intelligence at AIMS by [François Fleuret](https://www.idiap.ch/~fleuret/). This course covers the main deep learning tools and theoretical results, with examples in the PyTorch framework.
* Mini Course in [Deep Learning with PyTorch](https://github.com/Atcold/pytorch-Deep-Learning-Minicourse) for AIMS given by **Alfredo Canziani and Ritchie Ng**.


---
# Reinforcement Learning
---


* You can find here [[slides](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html),[videos](https://www.youtube.com/watch?v=2pWv7GOvuf0)] for the Reinforcement Learning Course (10 lectures) given by **David Silver** at University College London.


---
# Kernel Methods for Machine Learning
---

This course covers basic concepts in machine learning in high dimension, and the importance of regularization. We study in detail high-dimensional linear models regularized by the Euclidean norm, including ridge regression, ridge logistic regression and support vector machines. We then show how positive definite kernels allows to transform these linear models into rich nonlinear models, usable even for non-vectorial data such as strings and graphs, and convenient for integrating heterogeneous data.
* You can find here [slides + Practicals + data](http://members.cbio.mines-paristech.fr/~jvert/svn/kernelcourse/course/2019ammi/index.html)all the necessary materials slides, practical and data for the data challenge for the Kernel Methods for Machine Learning Course given by **Jean-Philippe Vert** from the Centre for Computational Biology at Mines ParisTech and Google Brain.


---
# Optimization for Machine Learning
---

Many estimation problems in statistical learning are formulated as optimization problems. These formulations allowed a separation between the analysis of the estimator's performance and the development of problem-solving algorithms. Faced with large volumes of data, such separation is no longer effective and analysis must combine statistics and optimization. In this course, the classic statistical results on M-estimation and convex optimization will be presented in a unified way, showing the links between statistics and optimization. Emphasis will be placed on non-asymptotic analysis of stochastic approximation and stochastic gradient.
* You can find here slides [[Part II](https://www.di.ens.fr/~fbach/orsay2019.html) ,[Part II](https://perso.telecom-paristech.fr/rgower/teaching.html)] for the Optimization for Machine Learning Course given by **Francis Bach** from INRIA - Ecole Normale Supérieure  and **Robert M. Gower** from Telecom-Paristech.


---
# Probabilistic Graphical Models
---

This course provides a unifying introduction to probabilistic modelling through the framework of graphical models, together with their associated learning and inference algorithms. 
* You can find here [slides](https://github.com/timlacroix/pgm_ammi) for the Probabilistic Graphical Models Course given by **Guillaume Obozinski** from Ecole des Ponts, ParisTech - INRIA/ENS.
