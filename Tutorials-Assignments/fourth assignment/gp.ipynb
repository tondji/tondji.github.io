{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ##############################################################################\n",
    "# LoadData takes the file location for the yacht_hydrodynamics.data and returns\n",
    "# the data set partitioned into a training set and a test set.\n",
    "# the X matrix, deal with the month and day strings.\n",
    "# Do not change this function!\n",
    "# ##############################################################################\n",
    "def loadData(df):\n",
    "    data = np.loadtxt(df)\n",
    "    Xraw = data[:,:-1]\n",
    "    # The regression task is to predict the residuary resistance per unit weight of displacement\n",
    "    yraw = (data[:,-1])[:, None]\n",
    "    X = (Xraw-Xraw.mean(axis=0))/np.std(Xraw, axis=0)\n",
    "    y = (yraw-yraw.mean(axis=0))/np.std(yraw, axis=0)\n",
    "\n",
    "    ind = range(X.shape[0])\n",
    "    test_ind = ind[0::4] # take every fourth observation for the test set\n",
    "    train_ind = list(set(ind)-set(test_ind))\n",
    "    X_test = X[test_ind]\n",
    "    X_train = X[train_ind]\n",
    "    y_test = y[test_ind]\n",
    "    y_train = y[train_ind]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ##############################################################################\n",
    "# Returns a single sample from a multivariate Gaussian with mean and cov.\n",
    "# ##############################################################################\n",
    "def multivariateGaussianDraw(mean, cov):\n",
    "    \n",
    "    #n = mean.shape[0]\n",
    "    #sample = np.zeros((mean.shape[0], 1)) # This is only a placeholder\n",
    "    # Task 2:\n",
    "    # TODO: Implement a draw from a multivariate Gaussian here\n",
    "    \n",
    "#     K = np.linalg.cholesky(cov + 1e-15*np.eye(n))\n",
    "#     sample = np.dot(L, np.random.normal(size=(n,1)))\n",
    "    sample = np.random.multivariate_normal(mean, cov, 1)\n",
    "\n",
    "    # Return drawn sample\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ##############################################################################\n",
    "# RadialBasisFunction for the kernel function\n",
    "# k(x,x') = s2_f*exp(-norm(x,x')^2/(2l^2)). If s2_n is provided, then s2_n is\n",
    "# added to the elements along the main diagonal, and the kernel function is for\n",
    "# the distribution of y,y* not f, f*.\n",
    "# ##############################################################################\n",
    "class RadialBasisFunction():\n",
    "    def __init__(self, params):\n",
    "        self.ln_sigma_f = params[0]\n",
    "        self.ln_length_scale = params[1]\n",
    "        self.ln_sigma_n = params[2]\n",
    "\n",
    "        self.sigma2_f = np.exp(2*self.ln_sigma_f)\n",
    "        self.sigma2_n = np.exp(2*self.ln_sigma_n)\n",
    "        self.length_scale = np.exp(self.ln_length_scale)\n",
    "\n",
    "    def setParams(self, params):\n",
    "        self.ln_sigma_f = params[0]\n",
    "        self.ln_length_scale = params[1]\n",
    "        self.ln_sigma_n = params[2]\n",
    "\n",
    "        self.sigma2_f = np.exp(2*self.ln_sigma_f)\n",
    "        self.sigma2_n = np.exp(2*self.ln_sigma_n)\n",
    "        self.length_scale = np.exp(self.ln_length_scale)\n",
    "\n",
    "    def getParams(self):\n",
    "        return np.array([self.ln_sigma_f, self.ln_length_scale, self.ln_sigma_n])\n",
    "\n",
    "    def getParamsExp(self):\n",
    "        return np.array([self.sigma2_f, self.length_scale, self.sigma2_n])\n",
    "\n",
    "    # ##########################################################################\n",
    "    # covMatrix computes the covariance matrix for the provided matrix X using\n",
    "    # the RBF. If two matrices are provided, for a training set and a test set,\n",
    "    # then covMatrix computes the covariance matrix between all inputs in the\n",
    "    # training and test set.\n",
    "    # ##########################################################################\n",
    "    def covMatrix(self, X, Xa=None):\n",
    "        if Xa is not None:\n",
    "            X_aug = np.zeros((X.shape[0]+Xa.shape[0], X.shape[1]))\n",
    "            X_aug[:X.shape[0], :X.shape[1]] = X\n",
    "            X_aug[X.shape[0]:, :X.shape[1]] = Xa\n",
    "            X=X_aug\n",
    "\n",
    "        n = X.shape[0]\n",
    "        covMat = np.zeros((n,n))\n",
    "\n",
    "        # Task 1:\n",
    "        # TODO: Implement the covariance matrix here\n",
    "        \n",
    "        \n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                sqdist = np.exp(-0.5 * (1/(self.length_scale)**2)* (np.linalg.norm(X[i,:]-X[j,:]))**2)\n",
    "                covMat[i,j] = self.sigma2_f *  sqdist\n",
    "        \n",
    "        \n",
    "\n",
    "        # If additive Gaussian noise is provided, this adds the sigma2_n along\n",
    "        # the main diagonal. So the covariance matrix will be for [y y*]. If\n",
    "        # you want [y f*], simply subtract the noise from the lower right\n",
    "        # quadrant.\n",
    "        if self.sigma2_n is not None:\n",
    "            covMat += self.sigma2_n*np.identity(n)\n",
    "\n",
    "        # Return computed covariance matrix\n",
    "        return covMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ln_sigma_f = np.log(1.27)\n",
    "# ln_length_scale = np.log(1)\n",
    "# ln_sigma_n = np.log(0.3)\n",
    "# basis = RadialBasisFunction([ln_sigma_f,ln_length_scale,ln_sigma_n])\n",
    "# X = np.array([-1.50,-1.00,-0.7,-0.40, -0.25, 0.00]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.linalg.det(basis.covMatrix(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train, y_train, X_test, y_test = loadData('yacht_hydrodynamics.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basis = RadialBasisFunction([ 1.10442998 ,17.38230593 ,-10.10133779])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.linalg.det(basis.covMatrix(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GaussianProcessRegression():\n",
    "    def __init__(self, X, y, k):\n",
    "        self.X = X\n",
    "        self.n = X.shape[0]\n",
    "        self.y = y\n",
    "        self.k = k\n",
    "        self.K = self.KMat(self.X)\n",
    "        self.L = np.linalg.cholesky(self.K)\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Recomputes the covariance matrix and the inverse covariance\n",
    "    # matrix when new hyperparameters are provided.\n",
    "    # ##########################################################################\n",
    "    def KMat(self, X, params=None):\n",
    "        if params is not None:\n",
    "            self.k.setParams(params)\n",
    "        K = self.k.covMatrix(X)\n",
    "        self.K = K\n",
    "        self.L = np.linalg.cholesky(self.K)\n",
    "        return K\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Computes the posterior mean of the Gaussian process regression and the\n",
    "    # covariance for a set of test points.\n",
    "    # NOTE: This should return predictions using the 'clean' (not noisy) covariance\n",
    "    # ##########################################################################\n",
    "    def predict(self, Xa):\n",
    "        mean_fa = np.zeros((Xa.shape[0], 1))\n",
    "        mean_fa = np.array(mean_fa.flatten())\n",
    "        cov_fa = np.zeros((Xa.shape[0], Xa.shape[0]))\n",
    "        # Task 3:\n",
    "        # TODO: compute the mean and covariance of the prediction\n",
    "        \n",
    "        \n",
    "        #beginning of my solution: ------->\n",
    "        na = Xa.shape[0]\n",
    "        Ktotal = self.k.covMatrix(self.X, Xa)\n",
    "        # Covariance between training sample points (without Gaussian noise)\n",
    "        Kxx = Ktotal[0:self.n,0:self.n] # + 1 * np.eye(10) if there is  Gaussian noise\n",
    "        \n",
    "        # Covariance between training and test points\n",
    "        Kxs = Ktotal[self.n:self.n+na, 0:self.n]\n",
    "        \n",
    "        # Covariance between test points\n",
    "        Kss = Ktotal[self.n:self.n+na,self.n:self.n+na]\n",
    "        \n",
    "        # The mean of the GP fit (note that @ is matrix multiplcation: A @ B is equivalent to np.matmul(A,B))\n",
    "        mean = Kxs @ np.linalg.inv(Kxx) @ self.y\n",
    "        \n",
    "        for i in range(mean.shape[0]):\n",
    "            mean_fa[i] = (mean[i])[0]\n",
    "        # The covariance matrix of the GP fit\n",
    "        cov_fa = Kss - Kxs @ np.linalg.inv(Kxx) @ Kxs.T\n",
    "        \n",
    "\n",
    "        # Return the mean and covariance\n",
    "        return mean_fa, cov_fa\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Return negative log marginal likelihood of training set. Needs to be\n",
    "    # negative since the optimiser only minimises.\n",
    "    # ##########################################################################\n",
    "    def logMarginalLikelihood(self, params=None):\n",
    "        if params is not None:\n",
    "            self.KMat(self.X, params)\n",
    "\n",
    "        mll = 0\n",
    "        # Task 4:\n",
    "        # TODO: Calculate the log marginal likelihood ( mll ) of self.y\n",
    "        \n",
    "        mll = 0.5* (self.y).T @ np.linalg.solve((self.L).T, np.linalg.solve(self.L, self.y)) + np.log(np.sum((self.L).diagonal())) + 0.5 * self.n * np.log(2 * np.pi)\n",
    "\n",
    "        # Return mll\n",
    "        return mll\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Computes the gradients of the negative log marginal likelihood wrt each\n",
    "    # hyperparameter.\n",
    "    # ##########################################################################\n",
    "    def gradLogMarginalLikelihood(self, params=None):\n",
    "        if params is not None:\n",
    "            K = self.KMat(self.X, params)\n",
    "\n",
    "        grad_ln_sigma_f = grad_ln_length_scale = grad_ln_sigma_n = 0\n",
    "        # Task 5:\n",
    "        # TODO: calculate the gradients of the negative log marginal likelihood\n",
    "        # wrt. the hyperparameters\n",
    "        \n",
    "        beta_ln_length_scale = np.zeros((self.n, self.n))\n",
    "        beta_ln_sigma_f = np.zeros((self.n, self.n))\n",
    "        beta_ln_sigma_n = np.zeros((self.n, self.n))\n",
    "        \n",
    "        param = self.k.getParamsExp()\n",
    "        \n",
    "        \n",
    "        alpha = np.linalg.solve(self.K, self.y)\n",
    "        #inv = np.linalg.solve((self.L).T, np.linalg.solve(self.L, np.eye(self.n,self.n)))\n",
    "        inv = np.linalg.inv(self.K)\n",
    "        #L = self.L\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.n):\n",
    "                beta_ln_length_scale[i,j] = (1/(param[1]**2)) * ((np.linalg.norm(self.X[i]-self.X[j]))**2) * param[0] * np.exp(-0.5*(np.linalg.norm(self.X[i]-self.X[j])**2)/(param[1]**2)) \n",
    "                beta_ln_sigma_n[i,j] =  2 * param[2] if (i==j) else 0\n",
    "                beta_ln_sigma_f[i,j] = 2 * param[0] * (np.exp(-0.5*(np.linalg.norm(self.X[i]-self.X[j])**2)/(param[1]**2)))\n",
    "        \n",
    "        #beta_ln_sigma_n =beta_ln_sigma_n @ \n",
    "        grad_ln_sigma_f = -0.5 * np.trace((alpha @ alpha.T - inv) @ beta_ln_sigma_f)\n",
    "        grad_ln_length_scale = -0.5 * np.trace((alpha @ alpha.T - inv) @ beta_ln_length_scale)\n",
    "        grad_ln_sigma_n = -0.5 * np.trace((alpha @ alpha.T - inv) @ beta_ln_sigma_n)\n",
    "        \n",
    "\n",
    "        # Combine gradients\n",
    "        gradients = np.array([grad_ln_sigma_f, grad_ln_length_scale, grad_ln_sigma_n])\n",
    "\n",
    "        # Return the gradients\n",
    "        return gradients\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Computes the mean squared error between two input vectors.\n",
    "    # ##########################################################################\n",
    "    def mse(self, ya, fbar):\n",
    "        mse = 0\n",
    "        # Task 7:\n",
    "        # TODO: Implement the MSE between ya and fbar\n",
    "        \n",
    "        mse = np.sum((ya[i,:] - fbar[i,:])**2)/(ya.shape[0])\n",
    "\n",
    "        # Return mse\n",
    "        return mse\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Computes the mean standardised log loss.\n",
    "    # ##########################################################################\n",
    "    def msll(self, ya, fbar, cov):\n",
    "        msll = 0\n",
    "        # Task 7:\n",
    "        # TODO: Implement MSLL of the prediction fbar, cov given the target ya\n",
    "\n",
    "        return msll\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Minimises the negative log marginal likelihood on the training set to find\n",
    "    # the optimal hyperparameters using BFGS.\n",
    "    # ##########################################################################\n",
    "    def optimize(self, params, disp=True):\n",
    "        \n",
    "        #params = np.array([0.5*np.log(1.0), np.log(1.0), 0.5*np.log(0.5)])\n",
    "        res = minimize(self.logMarginalLikelihood, params, method ='BFGS', jac = self.gradLogMarginalLikelihood, options = {'disp':disp})\n",
    "        return res.x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    ##########################\n",
    "    # You can put your tests here - marking\n",
    "    # will be based on importing this code and calling\n",
    "    # specific functions with custom input.\n",
    "    ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = loadData('yacht_hydrodynamics.data')\n",
    "params = [0.5*np.log(1.0), np.log(0.1), 0.5*np.log(0.5)]\n",
    "basis = RadialBasisFunction(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis.sigma2_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GPR = GaussianProcessRegression(X_train, y_train,basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.50000000e+000, 4.61008875e-002, 4.51686537e-006, ...,\n",
       "        4.26469604e-314, 0.00000000e+000, 0.00000000e+000],\n",
       "       [4.61008875e-002, 1.50000000e+000, 4.61008875e-002, ...,\n",
       "        1.04571091e-288, 4.26469604e-314, 0.00000000e+000],\n",
       "       [4.51686537e-006, 4.61008875e-002, 1.50000000e+000, ...,\n",
       "        5.44946378e-266, 1.04571091e-288, 4.26469604e-314],\n",
       "       ...,\n",
       "       [4.26469604e-314, 1.04571091e-288, 5.44946378e-266, ...,\n",
       "        1.50000000e+000, 4.61008875e-002, 4.51686537e-006],\n",
       "       [0.00000000e+000, 4.26469604e-314, 1.04571091e-288, ...,\n",
       "        4.61008875e-002, 1.50000000e+000, 4.61008875e-002],\n",
       "       [0.00000000e+000, 0.00000000e+000, 4.26469604e-314, ...,\n",
       "        4.51686537e-006, 4.61008875e-002, 1.50000000e+000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis.covMatrix(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 308)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(basis.covMatrix(X_train, X_test)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 231)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(GPR.KMat(X_train)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean, cov = GPR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 77)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[302.99403655]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPR.logMarginalLikelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 39.27007743, -11.97860468,  21.58116714])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPR.gradLogMarginalLikelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = multivariateGaussianDraw(mean, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = [0, 0]\n",
    "cov = [[1, 0], [0, 100]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngC8ikif+P9SAVLIuiJxMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0855662278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x, y = np.random.multivariate_normal(mean, cov, 5000).T\n",
    "plt.plot(x, y, 'x')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma2_f = np.exp(2*0.5*np.log(1.0))\n",
    "length_scale= np.exp(np.log(0.1))\n",
    "sigma2_n = np.exp(2*0.5*np.log(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def covariance(X,length_scale,sigma2_n,sigma2_f):\n",
    "    n = X.shape[0]\n",
    "    covMat = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "            for j in range(n):\n",
    "                sqdist = np.exp(-0.5 * (1/(length_scale)**2)* (np.linalg.norm(X[i,:]-X[j,:]))**2)\n",
    "                covMat[i,j] = sigma2_f *  sqdist\n",
    "                \n",
    "    \n",
    "    covMat += sigma2_n*np.identity(n)\n",
    "    \n",
    "    return covMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mll(X,y,length_scale,sigma2_n,sigma2_f):\n",
    "    n = X.shape[0]\n",
    "    K = covariance(X,length_scale,sigma2_n,sigma2_f)\n",
    "    L = np.linalg.cholesky(K)\n",
    "    mll = 0.5* y.T @ np.linalg.solve(L.T, np.linalg.solve(L, y)) + np.log(np.sum(L.diagonal())) + 0.5 * n * np.log(2 * np.pi)\n",
    "    \n",
    "    return mll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def gradient_checker():\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 231)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance(X_train,length_scale,sigma2_n,sigma2_f).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = 1e-6\n",
    "Gsigmaf_h = mll(X_train,y_train,length_scale,sigma2_n,sigma2_f + h)\n",
    "Gsigmaf = mll(X_train,y_train,length_scale,sigma2_n,sigma2_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-56.98667826]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Gsigmaf_h - Gsigmaf)/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[302.99403655]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mll(X_train,y_train,length_scale,sigma2_n,sigma2_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Gsigman_h = mll(X_train,y_train,length_scale,sigma2_n+h,sigma2_f)\n",
    "Gsigman = mll(X_train,y_train,length_scale,sigma2_n,sigma2_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-55.17528587]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Gsigman_h - Gsigman)/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Gl_h = mll(X_train,y_train,length_scale + h,sigma2_n,sigma2_f)\n",
    "Gl = mll(X_train,y_train,length_scale,sigma2_n,sigma2_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-111.49623032]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Gl_h - Gl)/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import check_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-a20b7b98d8fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGPR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogMarginalLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGPR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradLogMarginalLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/lionel/.local/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mcheck_grad\u001b[0;34m(func, grad, x0, *args, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m         raise ValueError(\"Unknown keyword arguments: %r\" %\n\u001b[1;32m    770\u001b[0m                          (list(kwargs.keys()),))\n\u001b[0;32m--> 771\u001b[0;31m     return sqrt(sum((grad(x0, *args) -\n\u001b[0m\u001b[1;32m    772\u001b[0m                      approx_fprime(x0, func, step, *args))**2))\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "check_grad(GPR.logMarginalLikelihood(), GPR.gradLogMarginalLikelihood(), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
