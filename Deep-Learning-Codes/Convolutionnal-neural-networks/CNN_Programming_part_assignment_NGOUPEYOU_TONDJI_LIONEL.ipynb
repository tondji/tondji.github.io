{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, n_feature, output_size, conv_kernel_size, pooling_kernel_size, stride_size, zero_padding, max_pooling):\n",
    "        super(CNN, self).__init__()\n",
    "        self.n_feature = n_feature\n",
    "        \n",
    "        if zero_padding :\n",
    "            self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=int(conv_kernel_size), stride = stride_size, padding = (int(conv_kernel_size)-1)//2)\n",
    "            self.conv2 = nn.Conv2d(16, 32, kernel_size=int(conv_kernel_size), stride = stride_size, padding = (int(conv_kernel_size)-1)//2)\n",
    "            self.sp = int(np.sqrt(input_size)/(pooling_kernel_size*pooling_kernel_size))\n",
    "            self.fc1 = nn.Linear(32*self.sp*self.sp, 10)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=int(conv_kernel_size), stride = stride_size)\n",
    "            self.conv2 = nn.Conv2d(16, 32, kernel_size=int(conv_kernel_size), stride = stride_size)\n",
    "            self.s = int((np.sqrt(input_size) + pooling_kernel_size * (stride_size**2 - stride_size*conv_kernel_size) + stride_size - conv_kernel_size)/(stride_size*pooling_kernel_size)**2 )\n",
    "            self.fc1 = nn.Linear(32*self.s*self.s, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        x = self.conv1(x)\n",
    "        if max_pooling :\n",
    "            x = F.max_pool2d(x, kernel_size=int(pooling_kernel_size))\n",
    "        else:\n",
    "            x = F.avg_pool2d(x, kernel_size=int(pooling_kernel_size))\n",
    "        x = self.conv2(x)\n",
    "        if max_pooling : \n",
    "            x = F.max_pool2d(x, kernel_size=int(pooling_kernel_size))\n",
    "        else:\n",
    "            x = F.avg_pool2d(x, kernel_size=int(pooling_kernel_size))\n",
    "            \n",
    "        self.zero_padding =zero_padding\n",
    "        if self.zero_padding :\n",
    "            x = x.view(-1, 32*self.sp*self.sp)\n",
    "        else:\n",
    "            x =x.view(-1, 32*self.s*self.s)\n",
    "        x = self.fc1(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Zero Padding Model Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_kernel_size = 5\n",
    "pooling_kernel_size = 2\n",
    "stride_size = 1\n",
    "zero_padding =True\n",
    "max_pooling =True\n",
    "\n",
    "\n",
    "\n",
    "input_size  = 28*28   # images are 28x28 pixels\n",
    "output_size = 10      # there are 10 classes\n",
    "n_feature = 6 # number of feature maps\n",
    "\n",
    "kwargs = {'input_size': 28*28, 'n_feature': 6,'output_size':10, 'conv_kernel_size': 5, 'pooling_kernel_size': 2, 'stride_size': 1, 'zero_padding':True, 'max_pooling': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n"
     ]
    }
   ],
   "source": [
    "print(model.conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n"
     ]
    }
   ],
   "source": [
    "print(model.conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 1568])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for k in model.parameters():\n",
    "    print(k.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 1568])\n",
      "torch.Size([10])\n",
      "28938\n"
     ]
    }
   ],
   "source": [
    "param_count = 0\n",
    "for param in model.parameters():\n",
    "  print(param.data.shape)\n",
    "  param_count += np.product(param.data.shape)\n",
    "print(param_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of CNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (fc1): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Valid Padding Model Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_kernel_size = 5\n",
    "pooling_kernel_size = 2\n",
    "stride_size = 1\n",
    "zero_padding = False\n",
    "max_pooling = True\n",
    "\n",
    "\n",
    "input_size  = 28*28   # images are 28x28 pixels\n",
    "output_size = 10      # there are 10 classes\n",
    "n_feature = 6 # number of feature maps\n",
    "\n",
    "kwargs = {'input_size': 28*28, 'n_feature': 6,'output_size':10, 'conv_kernel_size': 5, 'pooling_kernel_size': 2, 'stride_size': 1, 'zero_padding':False, 'max_pooling': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = CNN(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of CNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=512, out_features=10, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model1.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for k in model1.parameters():\n",
    "    print(k.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10])\n",
      "18378\n"
     ]
    }
   ],
   "source": [
    "param_count = 0\n",
    "for param in model1.parameters():\n",
    "  print(param.data.shape)\n",
    "  param_count += np.product(param.data.shape)\n",
    "print(param_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "print(model1.conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "print(model1.conv2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
