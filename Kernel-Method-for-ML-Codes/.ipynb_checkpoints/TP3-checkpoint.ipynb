{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP3 Kernel Methods for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import numpy as np\n",
    "from sklearn import linear_model as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:07:29) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement (naive) solvers to Ridge Regression, Weighted Ridge Regression and Logistic Ridge Regression (using Iteratively Reweighted Least Squares). See notes for the mathematical derivation.\n",
    "2. Simulate some toy data to check if our solvers give correct solutions as provided by R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge Regression (RR)**\n",
    "\n",
    "Given $X \\in \\mathbb{R}^{n \\times p}$ and $y \\in \\mathbb{R}^n$, solve\n",
    "$$\n",
    "\\min_{\\beta \\in \\mathbb{R}^p} \\frac{1}{n} \\|y - X \\beta\\|^2 + \\lambda \\|\\beta\\|^2 \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression (RR)\n",
    "def solveRR(y, X, lam):\n",
    "    n,p = X.shape\n",
    "    assert (len(y) == n)\n",
    "    \n",
    "    A = X.T @ X\n",
    "    # Adjust diagonal due to Ridge\n",
    "    A[np.diag_indices_from(A)] += lam*n\n",
    "    b = X.T.dot(y)\n",
    "    \n",
    "    # Find solution to the linear system Ax = b\n",
    "    beta = np.linalg.solve(A,b)\n",
    "    return (beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weighted Ridge Regression (WRR)**\n",
    "\n",
    "Given $X \\in \\mathbb{R}^{n \\times p}$ and $y \\in \\mathbb{R}^n$, and weights $w \\in \\mathbb{R}^n_+$, solve\n",
    "$$\n",
    "\\min_{\\beta \\in \\mathbb{R}^p} \\frac{1}{n} \\sum_{i=1}^n w_i (y_i - \\beta^\\top x_i)^2 + \\lambda \\|\\beta\\|^2 \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Ridge Regression (WRR)\n",
    "def solveWRR(y, X, w, lam):\n",
    "    y1 = np.sqrt(w)*y\n",
    "    X1 = (np.sqrt(w)*X.T).T\n",
    "    \n",
    "    beta = solveRR(y1, X1, lam)\n",
    "    return (beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Ridge Regression (LRR)**\n",
    "\n",
    "Given $X \\in \\mathbb{R}^{n \\times p}$ and $y \\in \\{-1,+1\\}^n$, solve\n",
    "$$\n",
    "\\min_{\\beta \\in \\mathbb{R}^p} \\frac{1}{n} \\sum_{i=1}^n \\log (1+e^{-y_i \\beta^\\top x_i}) + \\lambda \\|\\beta\\|^2 \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Ridge Regression (LRR)\n",
    "def solveLRR(y, X, lam):\n",
    "    # Parameters\n",
    "    L = 100\n",
    "    eps = 1e-3\n",
    "    sigmoid = lambda a: 1/(1+np.exp(-a))\n",
    "    n,p = X.shape\n",
    "    \n",
    "    # Initialize\n",
    "    beta = np.zeros(p)\n",
    "    \n",
    "    # Update (equiv to IRLS)\n",
    "    for k in range(L):\n",
    "        beta_old = beta\n",
    "        f = X.dot(beta_old)\n",
    "        w = sigmoid(f) * sigmoid(-f)\n",
    "        z = f + y / sigmoid(y*f)\n",
    "        beta = solveWRR(z, X, w, 2*lam)\n",
    "        if np.sum((beta-beta_old)**2) < eps:\n",
    "            break\n",
    "        \n",
    "    return (beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Toy experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0619487467095844e-32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Toy data\n",
    "np.random.seed(12345)\n",
    "n = 100\n",
    "p = 20\n",
    "X = np.random.normal(0,1,(n,p))\n",
    "X = sklearn.preprocessing.scale(X)\n",
    "y = np.sign(np.random.normal(0,1,n))\n",
    "lam = 0.01\n",
    "\n",
    "# Our solver\n",
    "beta1 = solveRR(y, X, lam) # RR\n",
    "# beta1 = solveLRR(y, X, lam) # LRR\n",
    "# print(beta1)\n",
    "\n",
    "# Python solver\n",
    "beta2 = lm.Ridge(alpha=lam*n,fit_intercept=False,normalize=False).fit(X, y).coef_ # RR\n",
    "# beta2 = lm.RidgeClassifier(alpha=2*n*lam,fit_intercept=False,normalize=False).fit(X, y).coef_ # LRR gives different results?\n",
    "# print(beta2)\n",
    "\n",
    "# Check\n",
    "np.sum((beta1-beta2)**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
