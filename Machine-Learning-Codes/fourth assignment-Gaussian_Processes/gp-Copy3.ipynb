{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# ##############################################################################\n",
    "# LoadData takes the file location for the yacht_hydrodynamics.data and returns\n",
    "# the data set partitioned into a training set and a test set.\n",
    "# the X matrix, deal with the month and day strings.\n",
    "# Do not change this function!\n",
    "# ##############################################################################\n",
    "def loadData(df):\n",
    "    data = np.loadtxt(df)\n",
    "    Xraw = data[:,:-1]\n",
    "    # The regression task is to predict the residuary resistance per unit weight of displacement\n",
    "    yraw = (data[:,-1])[:, None]\n",
    "    X = (Xraw-Xraw.mean(axis=0))/np.std(Xraw, axis=0)\n",
    "    y = (yraw-yraw.mean(axis=0))/np.std(yraw, axis=0)\n",
    "\n",
    "    ind = range(X.shape[0])\n",
    "    test_ind = ind[0::4] # take every fourth observation for the test set\n",
    "    train_ind = list(set(ind)-set(test_ind))\n",
    "    X_test = X[test_ind]\n",
    "    X_train = X[train_ind]\n",
    "    y_test = y[test_ind]\n",
    "    y_train = y[train_ind]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# ##############################################################################\n",
    "# Returns a single sample from a multivariate Gaussian with mean and cov.\n",
    "# ##############################################################################\n",
    "def multivariateGaussianDraw(mean, cov):\n",
    "    \n",
    "    sample = np.zeros((mean.shape[0], )) # This is only a placeholder\n",
    "    # Task 2:\n",
    "    # TODO: Implement a draw from a multivariate Gaussian here\n",
    "    \n",
    "    sample = np.random.multivariate_normal(mean, cov, 1)\n",
    "\n",
    "    # Return drawn sample\n",
    "    return sample\n",
    "\n",
    "# ##############################################################################\n",
    "# RadialBasisFunction for the kernel function\n",
    "# k(x,x') = s2_f*exp(-norm(x,x')^2/(2l^2)). If s2_n is provided, then s2_n is\n",
    "# added to the elements along the main diagonal, and the kernel function is for\n",
    "# the distribution of y,y* not f, f*.\n",
    "# ##############################################################################\n",
    "class RadialBasisFunction():\n",
    "    def __init__(self, params):\n",
    "        self.ln_sigma_f = params[0]\n",
    "        self.ln_length_scale = params[1]\n",
    "        self.ln_sigma_n = params[2]\n",
    "\n",
    "        self.sigma2_f = np.exp(2*self.ln_sigma_f)\n",
    "        self.sigma2_n = np.exp(2*self.ln_sigma_n)\n",
    "        self.length_scale = np.exp(self.ln_length_scale)\n",
    "\n",
    "    def setParams(self, params):\n",
    "        self.ln_sigma_f = params[0]\n",
    "        self.ln_length_scale = params[1]\n",
    "        self.ln_sigma_n = params[2]\n",
    "\n",
    "        self.sigma2_f = np.exp(2*self.ln_sigma_f)\n",
    "        self.sigma2_n = np.exp(2*self.ln_sigma_n)\n",
    "        self.length_scale = np.exp(self.ln_length_scale)\n",
    "\n",
    "    def getParams(self):\n",
    "        return np.array([self.ln_sigma_f, self.ln_length_scale, self.ln_sigma_n])\n",
    "\n",
    "    def getParamsExp(self):\n",
    "        return np.array([self.sigma2_f, self.length_scale, self.sigma2_n])\n",
    "\n",
    "    # ##########################################################################\n",
    "    # covMatrix computes the covariance matrix for the provided matrix X using\n",
    "    # the RBF. If two matrices are provided, for a training set and a test set,\n",
    "    # then covMatrix computes the covariance matrix between all inputs in the\n",
    "    # training and test set.\n",
    "    # ##########################################################################\n",
    "    def covMatrix(self, X, Xa=None):\n",
    "        if Xa is not None:\n",
    "            X_aug = np.zeros((X.shape[0]+Xa.shape[0], X.shape[1]))\n",
    "            X_aug[:X.shape[0], :X.shape[1]] = X\n",
    "            X_aug[X.shape[0]:, :X.shape[1]] = Xa\n",
    "            X=X_aug\n",
    "\n",
    "        n = X.shape[0]\n",
    "        covMat = np.zeros((n,n))\n",
    "\n",
    "        # Task 1:\n",
    "        # TODO: Implement the covariance matrix here\n",
    "        \n",
    "        \n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                sqdist = np.exp(-0.5 * (1/(self.length_scale)**2)* (np.linalg.norm(X[i,:]-X[j,:]))**2)\n",
    "                covMat[i,j] = self.sigma2_f *  sqdist\n",
    "        \n",
    "\n",
    "        # If additive Gaussian noise is provided, this adds the sigma2_n along\n",
    "        # the main diagonal. So the covariance matrix will be for [y y*]. If\n",
    "        # you want [y f*], simply subtract the noise from the lower right\n",
    "        # quadrant.\n",
    "        if self.sigma2_n is not None:\n",
    "            covMat += self.sigma2_n*np.identity(n)\n",
    "\n",
    "        # Return computed covariance matrix\n",
    "        return covMat\n",
    "\n",
    "class GaussianProcessRegression():\n",
    "    def __init__(self, X, y, k):\n",
    "        self.X = X\n",
    "        self.n = X.shape[0]\n",
    "        self.y = y\n",
    "        self.k = k\n",
    "        self.K = self.KMat(self.X)\n",
    "        self.L = np.linalg.cholesky(self.K)\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Recomputes the covariance matrix and the inverse covariance\n",
    "    # matrix when new hyperparameters are provided.\n",
    "    # ##########################################################################\n",
    "    def KMat(self, X, params=None):\n",
    "        if params is not None:\n",
    "            self.k.setParams(params)\n",
    "        K = self.k.covMatrix(X)\n",
    "        self.K = K\n",
    "        self.L = np.linalg.cholesky(self.K)\n",
    "        return K\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Computes the posterior mean of the Gaussian process regression and the\n",
    "    # covariance for a set of test points.\n",
    "    # NOTE: This should return predictions using the 'clean' (not noisy) covariance\n",
    "    # ##########################################################################\n",
    "    def predict(self, Xa):\n",
    "        mean_fa = np.zeros((Xa.shape[0], 1))\n",
    "        mean_fa = np.array(mean_fa.flatten())\n",
    "        cov_fa = np.zeros((Xa.shape[0], Xa.shape[0]))\n",
    "        # Task 3:\n",
    "        # TODO: compute the mean and covariance of the prediction\n",
    "        \n",
    "        \n",
    "        #beginning of my solution: ------->\n",
    "        na = Xa.shape[0]\n",
    "        params = self.k.getParamsExp()\n",
    "        Ktotal = self.k.covMatrix(self.X, Xa)\n",
    "        # Covariance between training sample points (without Gaussian noise)\n",
    "        Kxx = Ktotal[0:self.n,0:self.n] # + 1 * np.eye(10) if there is  Gaussian noise\n",
    "        \n",
    "        # Covariance between training and test points\n",
    "        Kxs = Ktotal[self.n:self.n+na, 0:self.n]\n",
    "        \n",
    "        # Covariance between test points\n",
    "        Kss = self.k.covMatrix(Xa)  #- params[2] * np.eye((na,na))  #Ktotal[self.n:self.n+na,self.n:self.n+na] #- params[2]@ np.eye((na,na))\n",
    "        for i in range(Kss.shape[0]):\n",
    "                Kss[i,i] = Kss[i,i] - params[2]\n",
    "        \n",
    "        # The mean of the GP fit (note that @ is matrix multiplcation: A @ B is equivalent to np.matmul(A,B))\n",
    "        mean = Kxs @ np.linalg.inv(Kxx) @ self.y\n",
    "        \n",
    "        for i in range(mean.shape[0]):\n",
    "            mean_fa[i] = (mean[i])[0]\n",
    "        # The covariance matrix of the GP fit\n",
    "        cov_fa = Kss - Kxs @ np.linalg.inv(Kxx) @ Kxs.T\n",
    "        \n",
    "\n",
    "        # Return the mean and covariance\n",
    "        return mean_fa, cov_fa\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Return negative log marginal likelihood of training set. Needs to be\n",
    "    # negative since the optimiser only minimises.\n",
    "    # ##########################################################################\n",
    "    def logMarginalLikelihood(self, params=None):\n",
    "        if params is not None:\n",
    "            self.KMat(self.X, params)\n",
    "\n",
    "        mll = 0\n",
    "        # Task 4:\n",
    "        # TODO: Calculate the log marginal likelihood ( mll ) of self.y\n",
    "        \n",
    "        mll = 0.5* (self.y).T @ np.linalg.solve((self.L).T, np.linalg.solve(self.L, self.y)) + np.sum(np.log((self.L).diagonal())) + 0.5 * self.n * np.log(2 * np.pi)\n",
    "        mll = mll[0][0]\n",
    "        # Return mll\n",
    "        return mll\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Computes the gradients of the negative log marginal likelihood wrt each\n",
    "    # hyperparameter.\n",
    "    # ##########################################################################\n",
    "    def gradLogMarginalLikelihood(self, params=None):\n",
    "        if params is not None:\n",
    "            K = self.KMat(self.X, params)\n",
    "\n",
    "        grad_ln_sigma_f = grad_ln_length_scale = grad_ln_sigma_n = 0\n",
    "        # Task 5:\n",
    "        # TODO: calculate the gradients of the negative log marginal likelihood\n",
    "        # wrt. the hyperparameters\n",
    "        \n",
    "        beta_ln_length_scale = np.zeros((self.n, self.n))\n",
    "        beta_ln_sigma_f = np.zeros((self.n, self.n))\n",
    "        beta_ln_sigma_n = np.zeros((self.n, self.n))\n",
    "        \n",
    "        param = self.k.getParamsExp() #np.array([self.sigma2_f, self.length_scale, self.sigma2_n])\n",
    "        \n",
    "        \n",
    "        alpha = np.linalg.solve(self.K, self.y)\n",
    "        #inv = np.linalg.solve((self.L).T, np.linalg.solve(self.L, np.eye(self.n,self.n)))\n",
    "        inv = np.linalg.inv(self.K)\n",
    "        #L = self.L\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.n):\n",
    "                const = (np.linalg.norm(self.X[i]-self.X[j]))**2\n",
    "                beta_ln_sigma_f[i,j] = 2 * param[0] * np.exp(-0.5 * const/(param[1]**2))\n",
    "                beta_ln_length_scale[i,j] = (param[0]/(param[1]**2)) * const * np.exp(-0.5 * const/(param[1]**2)) \n",
    "                beta_ln_sigma_n[i,j] =  2 * param[2] if (i==j) else 0\n",
    "        \n",
    "        #beta_ln_sigma_n =beta_ln_sigma_n @ \n",
    "        grad_ln_sigma_f = -0.5 * np.trace((alpha @ alpha.T - inv) @ beta_ln_sigma_f)\n",
    "        grad_ln_length_scale = -0.5 * np.trace((alpha @ alpha.T - inv) @ beta_ln_length_scale)\n",
    "        grad_ln_sigma_n = -0.5 * np.trace((alpha @ alpha.T - inv) @ beta_ln_sigma_n)\n",
    "        \n",
    "\n",
    "        # Combine gradients\n",
    "        gradients = np.array([grad_ln_sigma_f, grad_ln_length_scale, grad_ln_sigma_n])\n",
    "\n",
    "        # Return the gradients\n",
    "        return gradients\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Computes the mean squared error between two input vectors.\n",
    "    # ##########################################################################\n",
    "    def mse(self, ya, fbar):\n",
    "        mse = 0\n",
    "        # Task 7:\n",
    "        # TODO: Implement the MSE between ya and fbar\n",
    "        \n",
    "        for i in range(ya.shape[0]):\n",
    "            mse += np.sum((ya[i] - fbar[i])**2)/(ya.shape[0])\n",
    "\n",
    "        # Return mse\n",
    "        return mse\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Computes the mean standardised log loss.\n",
    "    # ##########################################################################\n",
    "    def msll(self, ya, fbar, cov):\n",
    "        msll = 0\n",
    "        # Task 7:\n",
    "        # TODO: Implement MSLL of the prediction fbar, cov given the target ya\n",
    "        \n",
    "        param = self.k.getParamsExp()\n",
    "        sigma = np.diagonal(cov) \n",
    "        \n",
    "        for i in range(ya.shape[0]):\n",
    "            msll += 0.5 * np.log(2* np.pi * sigma[i]) + ((ya[i] - fbar[i])**2)/(2 * sigma[i])\n",
    "            \n",
    "        msll = msll/(ya.shape[0])\n",
    "\n",
    "        return msll\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Minimises the negative log marginal likelihood on the training set to find\n",
    "    # the optimal hyperparameters using BFGS.\n",
    "    # ##########################################################################\n",
    "    def optimize(self, params, disp=True):\n",
    "        \n",
    "        res = minimize(self.logMarginalLikelihood, params, method ='BFGS', jac = self.gradLogMarginalLikelihood, options = {'disp':disp})\n",
    "        return res.x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    ##########################\n",
    "    # You can put your tests here - marking\n",
    "    # will be based on importing this code and calling\n",
    "    # specific functions with custom input.\n",
    "    ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = loadData('yacht_hydrodynamics.data')\n",
    "params = [0.5*np.log(1.0), np.log(0.1), 0.5*np.log(0.5)]\n",
    "basis = RadialBasisFunction(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GPR = GaussianProcessRegression(X_train, y_train,basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 231)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis.covMatrix(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 308)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(basis.covMatrix(X_train, X_test)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 231)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(GPR.KMat(X_train)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean, cov = GPR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02017627, -0.03629425, -0.02006436,  0.0986253 , -0.03975349,\n",
       "       -0.03181455,  0.01355653, -0.02014108, -0.03581141, -0.01702384,\n",
       "        0.10249741, -0.03886745, -0.0296727 ,  0.01630726, -0.02002461,\n",
       "       -0.03570885, -0.01789738,  0.10318099, -0.03951629, -0.03137032,\n",
       "        0.01214956, -0.01984454, -0.03491483, -0.01720009,  0.09471578,\n",
       "       -0.03872453, -0.02895737,  0.01178568, -0.02007949, -0.0362516 ,\n",
       "       -0.02030838,  0.10966427, -0.03936436, -0.02942882,  0.02344937,\n",
       "       -0.02035499, -0.03644161, -0.01794647,  0.10505718, -0.03924066,\n",
       "       -0.03029931,  0.02080704, -0.02023602, -0.03643391, -0.01872925,\n",
       "        0.09951239, -0.03941362, -0.03247497,  0.02107363, -0.02025761,\n",
       "       -0.0366612 , -0.02080182,  0.12048901, -0.03981227, -0.03322858,\n",
       "        0.02170264, -0.02035493, -0.03574428, -0.01116493,  0.1086845 ,\n",
       "       -0.03986022, -0.02925268,  0.01530366, -0.02008186, -0.03577393,\n",
       "       -0.01579157,  0.13611811, -0.03937929, -0.03050932,  0.02011072,\n",
       "       -0.02039495, -0.03613201, -0.01560747,  0.09386845, -0.03979159,\n",
       "       -0.03008725,  0.01345952])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.98581806e-001, -1.32804949e-006,  3.77246149e-015, ...,\n",
       "         3.36566683e-158, -9.00239570e-164,  8.50876833e-172],\n",
       "       [-1.32804949e-006,  9.97163621e-001, -1.32804547e-006, ...,\n",
       "         3.36458509e-158,  3.36458508e-158, -9.00235343e-164],\n",
       "       [ 3.77246149e-015, -1.32804547e-006,  9.97163621e-001, ...,\n",
       "        -9.00235343e-164,  3.36458508e-158,  3.36458508e-158],\n",
       "       ...,\n",
       "       [ 3.36566683e-158,  3.36458509e-158, -9.00235343e-164, ...,\n",
       "         9.97163623e-001, -1.32804547e-006,  3.77245009e-015],\n",
       "       [-9.00239570e-164,  3.36458508e-158,  3.36458508e-158, ...,\n",
       "        -1.32804547e-006,  9.97163621e-001, -1.32804547e-006],\n",
       "       [ 8.50876833e-172, -9.00235343e-164,  3.36458508e-158, ...,\n",
       "         3.77245009e-015, -1.32804547e-006,  9.97163621e-001]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5397742114834622"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPR.mse(y_test,mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344.11280059438485"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPR.logMarginalLikelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+000 2.83697769e-001 1.11184378e-004 ... 6.15447964e-311\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [2.83697769e-001 0.00000000e+000 2.83697769e-001 ... 1.38682141e-285\n",
      "  6.15447964e-311 0.00000000e+000]\n",
      " [1.11184378e-004 2.83697769e-001 0.00000000e+000 ... 6.65697904e-263\n",
      "  1.38682141e-285 6.15447964e-311]\n",
      " ...\n",
      " [6.15447964e-311 1.38682141e-285 6.65697904e-263 ... 0.00000000e+000\n",
      "  2.83697769e-001 1.11184378e-004]\n",
      " [0.00000000e+000 6.15447964e-311 1.38682141e-285 ... 2.83697769e-001\n",
      "  0.00000000e+000 2.83697769e-001]\n",
      " [0.00000000e+000 0.00000000e+000 6.15447964e-311 ... 1.11184378e-004\n",
      "  2.83697769e-001 0.00000000e+000]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 39.27007743, -11.97860468,  21.58116714])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPR.gradLogMarginalLikelihood()\n",
    "#[19.636336629105244, -119.96975605541138, 21.582215086368706]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -160.372577\n",
      "         Iterations: 15\n",
      "         Function evaluations: 34\n",
      "         Gradient evaluations: 34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.74952692,  1.18679784, -3.70981841])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPR.optimize(np.array(params))\n",
    "# Warning: Desired error not necessarily achieved due to precision loss.\n",
    "#          Current function value: -160.314039\n",
    "#          Iterations: 12\n",
    "#          Function evaluations: 63\n",
    "#          Gradient evaluations: 53\n",
    "\n",
    "# array([ 2.81428412,  1.20090598, -3.71012936])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimiz.success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.18822945])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPR.msll(y_test, mean, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_y, cov_y = GPR.predict(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.28313176])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPR.msll(y_test, mean_y, cov_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.26936655,  0.43409084, -4.63542499])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimiz.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0533896295644682"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "fbar = np.random.multivariate_normal(mean, cov)\n",
    "GPR.mse(y_test, fbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma2_f = np.exp(2*0.5*np.log(1.0))\n",
    "length_scale= np.exp(np.log(0.1))\n",
    "sigma2_n = np.exp(2*0.5*np.log(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def covariance(X,length_scale,sigma2_n,sigma2_f):\n",
    "    n = X.shape[0]\n",
    "    covMat = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "            for j in range(n):\n",
    "                sqdist = np.exp(-0.5 * (1/(length_scale)**2)* (np.linalg.norm(X[i,:]-X[j,:]))**2)\n",
    "                covMat[i,j] = sigma2_f *  sqdist\n",
    "                \n",
    "    \n",
    "    covMat += sigma2_n*np.identity(n)\n",
    "    \n",
    "    return covMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mll(X,y,length_scale,sigma2_n,sigma2_f):\n",
    "    n = X.shape[0]\n",
    "    K = covariance(X,length_scale,sigma2_n,sigma2_f)\n",
    "    L = np.linalg.cholesky(K)\n",
    "    mll = 0.5* y.T @ np.linalg.solve(L.T, np.linalg.solve(L, y)) + np.sum(np.log((L).diagonal())) + 0.5 * n * np.log(2 * np.pi)\n",
    "    \n",
    "    return mll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 231)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance(X_train,length_scale,sigma2_n,sigma2_f).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = 1e-4\n",
    "sigma2_f_h = np.exp(2*(0.5*np.log(1.0) + h))\n",
    "length_scale_h = np.exp(np.log(0.1) + h)\n",
    "sigma2_n_h = np.exp(2*(0.5*np.log(0.5) +h))\n",
    "\n",
    "Gsigmaf_h = mll(X_train,y_train,length_scale,sigma2_n, sigma2_f_h)\n",
    "Gsigmaf = mll(X_train,y_train,length_scale,sigma2_n,sigma2_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.27919681]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Gsigmaf_h - Gsigmaf)/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[344.11280059]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mll(X_train,y_train,length_scale,sigma2_n,sigma2_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Gsigman_h = mll(X_train,y_train,length_scale,sigma2_n_h,sigma2_f)\n",
    "Gsigman = mll(X_train,y_train,length_scale,sigma2_n,sigma2_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21.58437356]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Gsigman_h - Gsigman)/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Gl_h = mll(X_train,y_train,length_scale_h,sigma2_n,sigma2_f)\n",
    "Gl = mll(X_train,y_train,length_scale,sigma2_n,sigma2_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-11.98104196]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Gl_h - Gl)/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[39.27919681075309, -11.981041961348637, 21.584373556606806]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[((Gsigmaf_h - Gsigmaf)/h)[0][0], ((Gl_h - Gl)/h)[0][0], ((Gsigman_h - Gsigman)/h)[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.37635738,  0.68915205,  1.16231755,  0.85475584,  0.26644606,\n",
       "         0.26615192,  0.80777712, -2.00578654,  0.54468847,  1.25883852,\n",
       "         0.1722827 , -0.0674602 , -2.17597851,  0.8040508 , -0.53632586,\n",
       "         1.67343025, -1.21788792, -1.26104046, -0.28439741,  0.33530352,\n",
       "         0.27491905, -0.31937151, -0.81590689,  0.25338032,  0.23529457,\n",
       "         0.79912838, -0.14011833, -1.13177478, -1.49853229, -1.75171792,\n",
       "        -0.00393174, -0.06600905, -1.30493592,  0.71343701,  0.73793125,\n",
       "        -0.52145806,  0.02721881,  0.66271595, -0.09418827,  1.07576977,\n",
       "        -0.15617355, -1.95761762, -0.24096041, -1.3272322 , -0.62485853,\n",
       "         0.1174323 , -0.37311705, -0.19361842,  0.50230348, -0.3480056 ,\n",
       "         0.60499786,  0.37096258,  0.57188482,  1.0483519 ,  0.08768342,\n",
       "        -0.6052435 , -0.93568761, -0.65403634,  0.56360926,  2.26477679,\n",
       "        -0.18122414,  0.68827425,  0.70304126,  0.07292968, -0.01923004,\n",
       "        -1.82706165, -0.79143402,  0.73965989,  0.54596012,  0.89624645,\n",
       "        -0.82810139,  0.19376707,  1.43176087, -0.75214714,  1.42272471,\n",
       "        -1.509094  , -0.71457834]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.multivariate_normal(mean, cov, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
