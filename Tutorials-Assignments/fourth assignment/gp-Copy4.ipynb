{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# ##############################################################################\n",
    "# LoadData takes the file location for the yacht_hydrodynamics.data and returns\n",
    "# the data set partitioned into a training set and a test set.\n",
    "# the X matrix, deal with the month and day strings.\n",
    "# Do not change this function!\n",
    "# ##############################################################################\n",
    "def loadData(df):\n",
    "    data = np.loadtxt(df)\n",
    "    Xraw = data[:,:-1]\n",
    "    # The regression task is to predict the residuary resistance per unit weight of displacement\n",
    "    yraw = (data[:,-1])[:, None]\n",
    "    X = (Xraw-Xraw.mean(axis=0))/np.std(Xraw, axis=0)\n",
    "    y = (yraw-yraw.mean(axis=0))/np.std(yraw, axis=0)\n",
    "\n",
    "    ind = range(X.shape[0])\n",
    "    test_ind = ind[0::4] # take every fourth observation for the test set\n",
    "    train_ind = list(set(ind)-set(test_ind))\n",
    "    X_test = X[test_ind]\n",
    "    X_train = X[train_ind]\n",
    "    y_test = y[test_ind]\n",
    "    y_train = y[train_ind]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# ##############################################################################\n",
    "# Returns a single sample from a multivariate Gaussian with mean and cov.\n",
    "# ##############################################################################\n",
    "def multivariateGaussianDraw(mean, cov):\n",
    "    \n",
    "    sample = np.zeros((mean.shape[0], )) # This is only a placeholder\n",
    "    # Task 2:\n",
    "    # TODO: Implement a draw from a multivariate Gaussian here\n",
    "    \n",
    "    sample = np.random.multivariate_normal(mean, cov, 1)\n",
    "\n",
    "    # Return drawn sample\n",
    "    return sample\n",
    "\n",
    "# ##############################################################################\n",
    "# RadialBasisFunction for the kernel function\n",
    "# k(x,x') = s2_f*exp(-norm(x,x')^2/(2l^2)). If s2_n is provided, then s2_n is\n",
    "# added to the elements along the main diagonal, and the kernel function is for\n",
    "# the distribution of y,y* not f, f*.\n",
    "# ##############################################################################\n",
    "class RadialBasisFunction():\n",
    "    def __init__(self, params):\n",
    "        self.ln_sigma_f = params[0]\n",
    "        self.ln_length_scale = params[1]\n",
    "        self.ln_sigma_n = params[2]\n",
    "\n",
    "        self.sigma2_f = np.exp(2*self.ln_sigma_f)\n",
    "        self.sigma2_n = np.exp(2*self.ln_sigma_n)\n",
    "        self.length_scale = np.exp(self.ln_length_scale)\n",
    "\n",
    "    def setParams(self, params):\n",
    "        self.ln_sigma_f = params[0]\n",
    "        self.ln_length_scale = params[1]\n",
    "        self.ln_sigma_n = params[2]\n",
    "\n",
    "        self.sigma2_f = np.exp(2*self.ln_sigma_f)\n",
    "        self.sigma2_n = np.exp(2*self.ln_sigma_n)\n",
    "        self.length_scale = np.exp(self.ln_length_scale)\n",
    "\n",
    "    def getParams(self):\n",
    "        return np.array([self.ln_sigma_f, self.ln_length_scale, self.ln_sigma_n])\n",
    "\n",
    "    def getParamsExp(self):\n",
    "        return np.array([self.sigma2_f, self.length_scale, self.sigma2_n])\n",
    "\n",
    "    # ##########################################################################\n",
    "    # covMatrix computes the covariance matrix for the provided matrix X using\n",
    "    # the RBF. If two matrices are provided, for a training set and a test set,\n",
    "    # then covMatrix computes the covariance matrix between all inputs in the\n",
    "    # training and test set.\n",
    "    # ##########################################################################\n",
    "    def covMatrix(self, X, Xa=None):\n",
    "        if Xa is not None:\n",
    "            X_aug = np.zeros((X.shape[0]+Xa.shape[0], X.shape[1]))\n",
    "            X_aug[:X.shape[0], :X.shape[1]] = X\n",
    "            X_aug[X.shape[0]:, :X.shape[1]] = Xa\n",
    "            X=X_aug\n",
    "\n",
    "        n = X.shape[0]\n",
    "        covMat = np.zeros((n,n))\n",
    "\n",
    "        # Task 1:\n",
    "        # TODO: Implement the covariance matrix here\n",
    "        \n",
    "        \n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                sqdist = np.exp(-0.5 * (1/(self.length_scale)**2)* (np.linalg.norm(X[i,:]-X[j,:]))**2)\n",
    "                covMat[i,j] = self.sigma2_f *  sqdist\n",
    "        \n",
    "\n",
    "        # If additive Gaussian noise is provided, this adds the sigma2_n along\n",
    "        # the main diagonal. So the covariance matrix will be for [y y*]. If\n",
    "        # you want [y f*], simply subtract the noise from the lower right\n",
    "        # quadrant.\n",
    "        if self.sigma2_n is not None:\n",
    "            covMat += self.sigma2_n*np.identity(n)\n",
    "\n",
    "        # Return computed covariance matrix\n",
    "        return covMat\n",
    "\n",
    "class GaussianProcessRegression():\n",
    "    def __init__(self, X, y, k):\n",
    "        self.X = X\n",
    "        self.n = X.shape[0]\n",
    "        self.y = y\n",
    "        self.k = k\n",
    "        self.K = self.KMat(self.X)\n",
    "        self.L = np.linalg.cholesky(self.K)\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Recomputes the covariance matrix and the inverse covariance\n",
    "    # matrix when new hyperparameters are provided.\n",
    "    # ##########################################################################\n",
    "    def KMat(self, X, params=None):\n",
    "        if params is not None:\n",
    "            self.k.setParams(params)\n",
    "        K = self.k.covMatrix(X)\n",
    "        self.K = K\n",
    "        self.L = np.linalg.cholesky(self.K)\n",
    "        return K\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Computes the posterior mean of the Gaussian process regression and the\n",
    "    # covariance for a set of test points.\n",
    "    # NOTE: This should return predictions using the 'clean' (not noisy) covariance\n",
    "    # ##########################################################################\n",
    "    def predict(self, Xa):\n",
    "        mean_fa = np.zeros((Xa.shape[0], 1))\n",
    "        mean_fa = np.array(mean_fa.flatten())\n",
    "        cov_fa = np.zeros((Xa.shape[0], Xa.shape[0]))\n",
    "        # Task 3:\n",
    "        # TODO: compute the mean and covariance of the prediction\n",
    "        \n",
    "        \n",
    "        #beginning of my solution: ------->\n",
    "        na = Xa.shape[0]\n",
    "        params = self.k.getParamsExp()\n",
    "        Ktotal = self.k.covMatrix(self.X, Xa)\n",
    "        # Covariance between training sample points (without Gaussian noise)\n",
    "        Kxx = Ktotal[0:self.n,0:self.n] # + 1 * np.eye(10) if there is  Gaussian noise\n",
    "        \n",
    "        # Covariance between training and test points\n",
    "        Kxs = Ktotal[self.n:self.n+na, 0:self.n]\n",
    "        \n",
    "        # Covariance between test points\n",
    "        Kss = self.k.covMatrix(Xa)  #- params[2] * np.eye((na,na))  #Ktotal[self.n:self.n+na,self.n:self.n+na] #- params[2]@ np.eye((na,na))\n",
    "        for i in range(Kss.shape[0]):\n",
    "                Kss[i,i] = Kss[i,i] - params[2]\n",
    "        \n",
    "        # The mean of the GP fit (note that @ is matrix multiplcation: A @ B is equivalent to np.matmul(A,B))\n",
    "        mean = Kxs @ np.linalg.inv(Kxx) @ self.y\n",
    "        \n",
    "        for i in range(mean.shape[0]):\n",
    "            mean_fa[i] = (mean[i])[0]\n",
    "        # The covariance matrix of the GP fit\n",
    "        cov_fa = Kss - Kxs @ np.linalg.inv(Kxx) @ Kxs.T\n",
    "        \n",
    "\n",
    "        # Return the mean and covariance\n",
    "        return mean_fa, cov_fa\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Return negative log marginal likelihood of training set. Needs to be\n",
    "    # negative since the optimiser only minimises.\n",
    "    # ##########################################################################\n",
    "    def logMarginalLikelihood(self, params=None):\n",
    "        if params is not None:\n",
    "            self.KMat(self.X, params)\n",
    "\n",
    "        mll = 0\n",
    "        # Task 4:\n",
    "        # TODO: Calculate the log marginal likelihood ( mll ) of self.y\n",
    "        \n",
    "        mll = 0.5* (self.y).T @ np.linalg.solve((self.L).T, np.linalg.solve(self.L, self.y)) + np.sum(np.log((self.L).diagonal())) + 0.5 * self.n * np.log(2 * np.pi)\n",
    "        mll = mll[0][0]\n",
    "        # Return mll\n",
    "        return mll\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Computes the gradients of the negative log marginal likelihood wrt each\n",
    "    # hyperparameter.\n",
    "    # ##########################################################################\n",
    "    def gradLogMarginalLikelihood(self, params=None):\n",
    "        if params is not None:\n",
    "            K = self.KMat(self.X, params)\n",
    "\n",
    "        grad_ln_sigma_f = grad_ln_length_scale = grad_ln_sigma_n = 0\n",
    "        # Task 5:\n",
    "        # TODO: calculate the gradients of the negative log marginal likelihood\n",
    "        # wrt. the hyperparameters\n",
    "        \n",
    "        beta_ln_length_scale = np.zeros((self.n, self.n))\n",
    "        beta_ln_sigma_f = np.zeros((self.n, self.n))\n",
    "        beta_ln_sigma_n = np.zeros((self.n, self.n))\n",
    "        \n",
    "        param = self.k.getParamsExp() #np.array([self.sigma2_f, self.length_scale, self.sigma2_n])\n",
    "        \n",
    "        \n",
    "        alpha = np.linalg.solve(self.K, self.y)\n",
    "        #inv = np.linalg.solve((self.L).T, np.linalg.solve(self.L, np.eye(self.n,self.n)))\n",
    "        inv = np.linalg.inv(self.K)\n",
    "        #L = self.L\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.n):\n",
    "                const = (np.linalg.norm(self.X[i]-self.X[j]))**2\n",
    "                beta_ln_sigma_f[i,j] = 2 * param[0] * np.exp(-0.5 * const/(param[1]**2))\n",
    "                beta_ln_length_scale[i,j] = (param[0]/(param[1]**2)) * const * np.exp(-0.5 * const/(param[1]**2)) \n",
    "                beta_ln_sigma_n[i,j] =  2 * param[2] if (i==j) else 0\n",
    "        \n",
    "        #beta_ln_sigma_n =beta_ln_sigma_n @ \n",
    "        grad_ln_sigma_f = -0.5 * np.trace((alpha @ alpha.T - inv) @ beta_ln_sigma_f)\n",
    "        grad_ln_length_scale = -0.5 * np.trace((alpha @ alpha.T - inv) @ beta_ln_length_scale)\n",
    "        grad_ln_sigma_n = -0.5 * np.trace((alpha @ alpha.T - inv) @ beta_ln_sigma_n)\n",
    "        \n",
    "\n",
    "        # Combine gradients\n",
    "        gradients = np.array([grad_ln_sigma_f, grad_ln_length_scale, grad_ln_sigma_n])\n",
    "\n",
    "        # Return the gradients\n",
    "        return gradients\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Computes the mean squared error between two input vectors.\n",
    "    # ##########################################################################\n",
    "    def mse(self, ya, fbar):\n",
    "        mse = 0\n",
    "        # Task 7:\n",
    "        # TODO: Implement the MSE between ya and fbar\n",
    "        \n",
    "        for i in range(ya.shape[0]):\n",
    "            mse += np.sum((ya[i] - fbar[i])**2)/(ya.shape[0])\n",
    "\n",
    "        # Return mse\n",
    "        return mse\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Computes the mean standardised log loss.\n",
    "    # ##########################################################################\n",
    "    def msll(self, ya, fbar, cov):\n",
    "        msll = 0\n",
    "        # Task 7:\n",
    "        # TODO: Implement MSLL of the prediction fbar, cov given the target ya\n",
    "        \n",
    "        param = self.k.getParamsExp()\n",
    "        sigma = np.diagonal(cov) \n",
    "        \n",
    "        for i in range(ya.shape[0]):\n",
    "            msll += 0.5 * np.log(2* np.pi * sigma[i]) + ((ya[i] - fbar[i])**2)/(2 * sigma[i])\n",
    "            \n",
    "        msll = msll/(ya.shape[0])\n",
    "\n",
    "        return msll\n",
    "\n",
    "    # ##########################################################################\n",
    "    # Minimises the negative log marginal likelihood on the training set to find\n",
    "    # the optimal hyperparameters using BFGS.\n",
    "    # ##########################################################################\n",
    "    def optimize(self, params, disp=True):\n",
    "        \n",
    "        res = minimize(self.logMarginalLikelihood, params, method ='BFGS', jac = self.gradLogMarginalLikelihood, options = {'disp':disp})\n",
    "        return res.x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    ##########################\n",
    "    # You can put your tests here - marking\n",
    "    # will be based on importing this code and calling\n",
    "    # specific functions with custom input.\n",
    "    ##########################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
