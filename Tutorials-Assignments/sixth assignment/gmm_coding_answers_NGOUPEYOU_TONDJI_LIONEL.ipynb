{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "\n",
    "class GaussianMixtureModel():\n",
    "    \"\"\"Density estimation with Gaussian Mixture Models (GMM).\n",
    "\n",
    "    You can add new functions if you find it useful, but **do not** change\n",
    "    the names or argument lists of the functions provided.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, K):\n",
    "        \"\"\"Initialise GMM class.\n",
    "\n",
    "        Arguments:\n",
    "          X -- data, N x D array\n",
    "          K -- number of mixture components, int\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.n = X.shape[0]\n",
    "        self.D = X.shape[1]\n",
    "        self.K = K\n",
    "\n",
    "\n",
    "    def E_step(self, mu, S, pi):\n",
    "        \"\"\"Compute the E step of the EM algorithm.\n",
    "\n",
    "        Arguments:\n",
    "          mu -- component means, K x D array\n",
    "          S -- component covariances, K x D x D array\n",
    "          pi -- component weights, K x 1 array\n",
    "\n",
    "        Returns:\n",
    "          r_new -- updated component responsabilities, N x K array\n",
    "        \"\"\"\n",
    "        # Assert that all arguments have the right shape\n",
    "        assert(mu.shape == (self.K, self.D) and\\\n",
    "               S.shape  == (self.K, self.D, self.D) and\\\n",
    "               pi.shape == (self.K, 1))\n",
    "        r_new = np.zeros((self.n, self.K))\n",
    "\n",
    "        # Task 1: implement the E step and return updated responsabilities\n",
    "        # Write your code from here...\n",
    "\n",
    "        for i in range(self.n): \n",
    "            Nk = 0\n",
    "            for j in range(self.K):\n",
    "                Nk += pi[j] * mvn.pdf((self.X)[i], mu[j], S[j], allow_singular=True)\n",
    "            for k in range(self.K):\n",
    "                r_new[i, k] = pi[k] * mvn.pdf((self.X)[i], mu[k], S[k], allow_singular=True)/ Nk\n",
    "        \n",
    "        # ... to here.\n",
    "        assert(r_new.shape == (self.n, self.K))\n",
    "        return r_new\n",
    "\n",
    "\n",
    "    def M_step(self, mu, r):\n",
    "        \"\"\"Compute the M step of the EM algorithm.\n",
    "\n",
    "        Arguments:\n",
    "          mu -- previous component means, K x D array\n",
    "          r -- previous component responsabilities,  N x K array\n",
    "\n",
    "        Returns:\n",
    "          mu_new -- updated component means, K x D array\n",
    "          S_new -- updated component covariances, K x D x D array\n",
    "          pi_new -- updated component weights, K x 1 array\n",
    "        \"\"\"\n",
    "        assert(mu.shape == (self.K, self.D) and\\\n",
    "               r.shape  == (self.n, self.K))\n",
    "        mu_new = np.zeros((self.K, self.D))\n",
    "        S_new  = np.zeros((self.K, self.D, self.D))\n",
    "        pi_new = np.zeros((self.K, 1))\n",
    "\n",
    "        # Task 2: implement the M step and return updated mixture parameters\n",
    "        # Write your code from here...\n",
    "\n",
    "        #updating mu and pi\n",
    "        for k in range(self.K):\n",
    "            Nk = 0\n",
    "            for j in range(self.n):\n",
    "                Nk += r[j,k]\n",
    "            for i in range(self.n):\n",
    "                mu_new[k] += (r[i, k] * (self.X)[i])\n",
    "            mu_new[k] /= Nk\n",
    "            pi_new[k] = Nk/ (self.n)\n",
    "        \n",
    "        #updating S\n",
    "        for k in range(self.K):\n",
    "            Nk = 0\n",
    "            for i in range(self.n): \n",
    "                Nk += r[i,k]\n",
    "            for i in range(self.n):\n",
    "                ys = np.reshape((self.X)[i]- mu_new[k], (-1,1))\n",
    "                S_new[k] += (r[i, k] * (ys @ (ys.T)))\n",
    "            S_new[k] /= Nk\n",
    "        \n",
    "        # ... to here.\n",
    "        assert(mu_new.shape == (self.K, self.D) and\\\n",
    "               S_new.shape  == (self.K, self.D, self.D) and\\\n",
    "               pi_new.shape == (self.K, 1))\n",
    "        return mu_new, S_new, pi_new\n",
    "\n",
    "    \n",
    "    def log_likelihood(self, pi, mu, S):\n",
    "        '''Compute the loglikelihood'''\n",
    "        \n",
    "        ll = 0\n",
    "        for i in range(self.n):\n",
    "                s = 0\n",
    "                for k in range(K):\n",
    "                    s += pi[k] * mvn.pdf((self.X)[i], mu[k], S[k], allow_singular=True)\n",
    "                ll += np.log(s)\n",
    "        return -ll\n",
    "    \n",
    "    def train(self, initial_params):\n",
    "        \"\"\"Fit a Gaussian Mixture Model (GMM) to the data in matrix X.\n",
    "\n",
    "        Arguments:\n",
    "          initial_params -- dictionary with fields 'mu', 'S', 'pi' and 'K'\n",
    "\n",
    "        Returns:kernel \n",
    "          mu -- component means, K x D array\n",
    "          S -- component covariances, K x D x D array\n",
    "          pi -- component weights, K x 1 array\n",
    "          r -- component responsabilities, N x K array\n",
    "        \"\"\"\n",
    "        # Assert that initial_params has all the necessary fields\n",
    "        assert(all([k in initial_params for k in ['mu', 'S', 'pi']]))\n",
    "\n",
    "        mu = np.zeros((self.K, self.D))\n",
    "        S  = np.zeros((self.K, self.D, self.D))\n",
    "        pi = np.zeros((self.K, 1))\n",
    "        r  = np.zeros((self.n, self.K))\n",
    "\n",
    "        # Task 3: implement the EM loop to train the GMM\n",
    "        # Write your code from here...\n",
    "        \n",
    "        # updating log likelihoood\n",
    "        eps = 1e-6  \n",
    "        K = initial_params['K']\n",
    "        mu = initial_params['mu']\n",
    "        S = initial_params['S']\n",
    "        pi = initial_params['pi']\n",
    "        \n",
    "        ll = 1\n",
    "        previous_ll = 0\n",
    "        \n",
    "        while(np.abs(ll-previous_ll) > eps):       \n",
    "            previous_ll = self.log_likelihood(pi, mu, S)\n",
    "            \n",
    "            r = self.E_step(mu, S, pi)\n",
    "            mu, S, pi =  self.M_step(mu, r)\n",
    "            ll = self.log_likelihood(pi, mu, S)\n",
    "\n",
    "        # ... to here.\n",
    "        assert(mu.shape == (self.K, self.D) and\\\n",
    "               S.shape  == (self.K, self.D, self.D) and\\\n",
    "               pi.shape == (self.K, 1) and\\\n",
    "               r.shape  == (self.n, self.K))\n",
    "        return mu, S, pi, r\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(43)\n",
    "\n",
    "    ##########################\n",
    "    # You can put your tests here - marking\n",
    "    # will be based on importing this code and calling\n",
    "    # specific functions with custom input.\n",
    "    # Do not write code outside the class definition or\n",
    "    # this if-block.\n",
    "    ##########################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
